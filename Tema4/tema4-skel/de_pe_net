#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <math.h>
 
#include <helper_cuda.h>
#include <helper_timer.h>
#include <helper_functions.h>
#include <helper_math.h>
 
// includes, project
#include "2Dconvolution.h"
 
#define LEN 5
 
////////////////////////////////////////////////////////////////////////////////
// declarations, forward
 
extern "C"
void computeGold(float*, const float*, const float*, unsigned int, unsigned int);
 
Matrix AllocateDeviceMatrix(int width, int height);
Matrix AllocateMatrix(int width, int height);
void FreeDeviceMatrix(Matrix* M);
void FreeMatrix(Matrix* M);
 
void ConvolutionOnDevice(const Matrix M, const Matrix N, Matrix P);
void ConvolutionOnDeviceShared(const Matrix M, const Matrix N, Matrix P);
 
////////////////////////////////////////////////////////////////////////////////
// Înmulțirea fără memorie partajată
////////////////////////////////////////////////////////////////////////////////
__global__ void ConvolutionKernel(Matrix M, Matrix N, Matrix P)
{
    float sum = 0;
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
 
    if (row < 0 || row >= N.height || col < 0 || col >= N.width) return;
 
    //TODO: calculul rezultatului convoluției
    for (int i=0; i<LEN; i++)
        for (int j=0; j<LEN; j++) {
 
                // Keep inside limits
                int nrow = row + i - 2;
                int ncol = col + j - 2;
 
                if (nrow >= 0 && nrow < N.height && ncol >= 0 && ncol < N.width)
                    sum += M.elements[i*M.width+j] * N.elements[(row+i-2)*N.width + (col+j-2)];
        }
 
    P.elements[row*P.width+col] = sum;
}
 
 
////////////////////////////////////////////////////////////////////////////////
// Înmulțirea cu memorie partajată
////////////////////////////////////////////////////////////////////////////////
__global__ void ConvolutionKernelShared(Matrix M, Matrix N, Matrix P)
{
 
    //TODO: calculul rezultatului convoluției
 
    int w = BLOCK_SIZE + LEN - 1;
    __shared__ float Nd[BLOCK_SIZE + LEN - 1][BLOCK_SIZE + LEN - 1];
    __shared__ float Md[KERNEL_SIZE][KERNEL_SIZE];
 
    if (threadIdx.x < LEN && threadIdx.y < LEN) {
        Md[threadIdx.y][threadIdx.x] = M.elements[threadIdx.y * M.width + threadIdx.x];
    }
 
    // First batch loading
    int dest = threadIdx.y * BLOCK_SIZE + threadIdx.x;
    int destY = dest / w;
    int destX = dest % w;
 
    int srcY = blockIdx.y * BLOCK_SIZE + destY - LEN / 2;
    int srcX = blockIdx.x * BLOCK_SIZE + destX - LEN / 2;
    //int src = (srcY * width + srcX) * channels + k;
 
    if (srcY >= 0 && srcY < N.height && srcX >= 0 && srcX < N.width)
        Nd[destY][destX] = N.elements[srcY * N.width + srcX];
    else
        Nd[destY][destX] = 0;
 
    // Second batch loading
    dest = threadIdx.y * BLOCK_SIZE + threadIdx.x + BLOCK_SIZE * BLOCK_SIZE;
    destY = dest / w;
    destX = dest % w;
 
    srcY = blockIdx.y * BLOCK_SIZE + destY - LEN / 2;
    srcX = blockIdx.x * BLOCK_SIZE + destX - LEN / 2;
 
    if (destY < w) {
        if (srcY >= 0 && srcY < N.height && srcX >= 0 && srcX < N.width)
            Nd[destY][destX] = N.elements[srcY * N.width + srcX];
        else
            Nd[destY][destX] = 0;
    }
 
    __syncthreads();
 
    float sum = 0;
    int y, x;
 
    for (y = 0; y < LEN; y++)
        for (x = 0; x < LEN; x++)
            sum += Nd[threadIdx.y + y][threadIdx.x + x] * Md[y][x];
 
    y = blockIdx.y * BLOCK_SIZE + threadIdx.y;
    x = blockIdx.x * BLOCK_SIZE + threadIdx.x;
 
    if (y < P.height && x < P.width)
        P.elements[y * N.width + x] = min(max(sum, 0.0), 1.0);
 
    //__syncthreads();
}
 
////////////////////////////////////////////////////////////////////////////////
// Returnează 1 dacă matricele sunt ~ egale
////////////////////////////////////////////////////////////////////////////////
int CompareMatrices(Matrix A, Matrix B)
{
    int i;
    if(A.width != B.width || A.height != B.height || A.pitch != B.pitch)
        return 0;
    int size = A.width * A.height;
    for(i = 0; i < size; i++) {
        printf("%f %f\n", A.elements[i], B.elements[i]);
        if(fabs(A.elements[i] - B.elements[i]) > MAX_ERR)
            return 0;
    }
    return 1;
}
void GenerateRandomMatrix(Matrix m)
{
    int i;
    int size = m.width * m.height;
 
    srand(time(NULL));
 
    for(i = 0; i < size; i++)
        m.elements[i] = rand() / (float)RAND_MAX;
}
 
////////////////////////////////////////////////////////////////////////////////
// main
////////////////////////////////////////////////////////////////////////////////
int main(int argc, char** argv)
{
    int width = 0, height = 0;
    FILE *f, *out;
    if(argc < 2)
    {
        printf("Argumente prea puține, trimiteți id-ul testului care trebuie rulat\n");
        return 0;
    }
    char name[100];
    sprintf(name, "./tests/test_%s.txt", argv[1]);
    f = fopen(name, "r");
    out = fopen("out.txt", "a");
    fscanf(f, "%d%d", &width, &height);
    Matrix M;//kernel de pe host
    Matrix N;//matrice inițială de pe host
    Matrix P;//rezultat fără memorie partajată calculat pe GPU
    Matrix PS;//rezultatul cu memorie partajată calculat pe GPU
   
    M = AllocateMatrix(KERNEL_SIZE, KERNEL_SIZE);
    N = AllocateMatrix(width, height);        
    P = AllocateMatrix(width, height);
    PS = AllocateMatrix(width, height);
 
    GenerateRandomMatrix(M);
    sleep(1); // Sleep to be sure elements differ
    GenerateRandomMatrix(N);
 
    // M * N pe device
    ConvolutionOnDevice(M, N, P);
   
    // M * N pe device cu memorie partajată
    ConvolutionOnDeviceShared(M, N, PS);
 
for (int i=0; i<PS.width*P.height; i++)
        printf("%f ", PS.elements[i]);
printf("\nPd\n");
 
    // calculează rezultatul pe CPU pentru comparație
    Matrix reference = AllocateMatrix(P.width, P.height);
    computeGold(reference.elements, M.elements, N.elements, N.height, N.width);
 
    // verifică dacă rezultatul obținut pe device este cel așteptat
    int res = CompareMatrices(reference, P);
    printf("Test global %s\n", (1 == res) ? "PASSED" : "FAILED");
    fprintf(out, "Test global %s %s\n", argv[1], (1 == res) ? "PASSED" : "FAILED");
 
    // verifică dacă rezultatul obținut pe device cu memorie partajată este cel așteptat
    int ress = CompareMatrices(reference, PS);
    printf("Test shared %s\n", (1 == ress) ? "PASSED" : "FAILED");
    fprintf(out, "Test shared %s %s\n", argv[1], (1 == ress) ? "PASSED" : "FAILED");
   
    // Free matrices
    FreeMatrix(&M);
    FreeMatrix(&N);
    FreeMatrix(&P);
    FreeMatrix(&PS);
 
    fclose(f);
    fclose(out);
    return 0;
}
 
 
////////////////////////////////////////////////////////////////////////////////
//! Run a simple test for CUDA
////////////////////////////////////////////////////////////////////////////////
void ConvolutionOnDevice(const Matrix M, const Matrix N, Matrix P)
{
    Matrix Md, Nd, Pd; //matricele corespunzătoare de pe device
 
    //pentru măsurarea timpului de execuție în kernel
    StopWatchInterface *kernelTime = NULL;
    sdkCreateTimer(&kernelTime);
    sdkResetTimer(&kernelTime);
 
    //TODO: alocați matricele de pe device
    cudaMalloc((void **)&Md.elements, M.width*M.height*sizeof(float));
    cudaMalloc((void **)&Nd.elements, N.width*N.height*sizeof(float));
    cudaMalloc((void **)&Pd.elements, P.width*P.height*sizeof(float));
 
    //TODO: copiați datele de pe host (M, N) pe device (MD, Nd)
    Md.width = M.width; Md.height = M.height;
    cudaMemcpy(Md.elements, M.elements, M.width*M.height*sizeof(float), cudaMemcpyHostToDevice);
    Nd.width = N.width; Nd.height = N.height;
    cudaMemcpy(Nd.elements, N.elements, N.width*N.height*sizeof(float), cudaMemcpyHostToDevice);
    Pd.width = P.width; Pd.height = P.height;
 
    //TODO: setați configurația de rulare a kernelului
    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);
 
    // Compute grid size
    int width = N.width;
    int height = N.height;
    while (width % BLOCK_SIZE !=0) width++;
    while (height % BLOCK_SIZE !=0) height++;
    dim3 dimGrid(width/BLOCK_SIZE, height/BLOCK_SIZE);
 
    sdkStartTimer(&kernelTime);
 
    //TODO: lansați în execuție kernelul
    ConvolutionKernel<<<dimGrid, dimBlock>>>(Md, Nd, Pd);
    cudaThreadSynchronize();
    sdkStopTimer(&kernelTime);
    printf ("Timp execuție kernel: %f ms\n", sdkGetTimerValue(&kernelTime));
    //TODO: copiaţi rezultatul pe host
    cudaMemcpy(P.elements, Pd.elements, Pd.width*Pd.height*sizeof(float), cudaMemcpyDeviceToHost);
 
    //TODO: eliberați memoria matricelor de pe device
    cudaFree(Md.elements);
    cudaFree(Nd.elements);
    cudaFree(Pd.elements);
}
 
 
void ConvolutionOnDeviceShared(const Matrix M, const Matrix N, Matrix P)
{
    Matrix Md, Nd, Pd; //matricele corespunzătoare de pe device
 
    //pentru măsurarea timpului de execuție în kernel
    StopWatchInterface *kernelTime = NULL;
    sdkCreateTimer(&kernelTime);
    sdkResetTimer(&kernelTime);
 
    //TODO: alocați matricele de pe device
    cudaMalloc((void **)&Md.elements, M.width*M.height*sizeof(float));
    cudaMalloc((void **)&Nd.elements, N.width*N.height*sizeof(float));
    cudaMalloc((void **)&Pd.elements, P.width*P.height*sizeof(float));
 
    //TODO: copiați datele de pe host (M, N) pe device (MD, Nd)
    Md.width = M.width; Md.height = M.height;
    cudaMemcpy(Md.elements, M.elements, M.width*M.height*sizeof(float), cudaMemcpyHostToDevice);
    Nd.width = N.width; Nd.height = N.height;
    cudaMemcpy(Nd.elements, N.elements, N.width*N.height*sizeof(float), cudaMemcpyHostToDevice);
    Pd.width = P.width; Pd.height = P.height;
 
    //TODO: setați configurația de rulare a kernelului
    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);
 
    // Compute grid size
    int width = N.width;
    int height = N.height;
    while (width % BLOCK_SIZE !=0) width++;
    while (height % BLOCK_SIZE !=0) height++;
    dim3 dimGrid(width/BLOCK_SIZE, height/BLOCK_SIZE);
 
    sdkStartTimer(&kernelTime);
 
    //TODO: lansați în execuție kernelul    
    ConvolutionKernelShared<<<dimGrid, dimBlock>>>(Md, Nd, Pd);
 
    cudaThreadSynchronize();
    sdkStopTimer(&kernelTime);
    printf ("Timp execuție kernel cu memorie partajată: %f ms\n", sdkGetTimerValue(&kernelTime));
 
    //TODO: copiaţi rezultatul pe host
    cudaMemcpy(P.elements, Pd.elements, Pd.width*Pd.height*sizeof(float), cudaMemcpyDeviceToHost);
 
    //TODO: eliberați memoria matricelor de pe device
    cudaFree(Md.elements);
    cudaFree(Nd.elements);
    cudaFree(Pd.elements);
}
 
 
// Alocă o matrice de dimensiune height*width pe device
Matrix AllocateDeviceMatrix(int width, int height)
{
    Matrix m;
    //TODO: alocați matricea și setați width, pitch și height
    return m;
}
 
// Alocă matrice pe host de dimensiune height*width
Matrix AllocateMatrix(int width, int height)
{
    Matrix M;
    M.width = M.pitch = width;
    M.height = height;
    int size = M.width * M.height;    
    M.elements = (float*) malloc(size*sizeof(float));
    return M;
}    
 
// Eliberează o matrice de pe device
void FreeDeviceMatrix(Matrix* M)
{
    cudaFree(M->elements);
    M->elements = NULL;
}
 
// Eliberează o matrice de pe host
void FreeMatrix(Matrix* M)
{
    free(M->elements);
    M->elements = NULL;
}